import React, { useEffect, useRef, useState } from "react";
import axios from "axios";

const Dashboard = () => {
  const [prediction, setPrediction] = useState("Listening...");
  const [waveform, setWaveform] = useState([]);
  const [waveColor, setWaveColor] = useState("#3498db");

  const canvasRef = useRef(null);
  const mediaRecorderRef = useRef(null);
  const chunksRef = useRef([]);
  const audioContextRef = useRef(null);
  const sourceRef = useRef(null);
  const analyserRef = useRef(null);
  const dataArrayRef = useRef(null);

  // Draw waveform when waveform data changes
  useEffect(() => {
    if (waveform.length > 0 && canvasRef.current) {
      const canvas = canvasRef.current;
      const ctx = canvas.getContext("2d");
      const width = canvas.width;
      const height = canvas.height;

      ctx.clearRect(0, 0, width, height);
      ctx.beginPath();
      ctx.moveTo(0, height / 2);

      waveform.forEach((point, i) => {
        const x = (i / waveform.length) * width;
        const y = height / 2 - point * height;
        ctx.lineTo(x, y);
      });

      ctx.strokeStyle = waveColor;
      ctx.lineWidth = 2;
      ctx.stroke();
    }
  }, [waveform, waveColor]);

  useEffect(() => {
    const startAudio = async () => {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });

        audioContextRef.current = new (window.AudioContext || window.webkitAudioContext)();
        sourceRef.current = audioContextRef.current.createMediaStreamSource(stream);

        analyserRef.current = audioContextRef.current.createAnalyser();
        analyserRef.current.fftSize = 2048;
        const bufferLength = analyserRef.current.fftSize;
        dataArrayRef.current = new Float32Array(bufferLength);

        sourceRef.current.connect(analyserRef.current);

        // Repeatedly get waveform data and update state
        const drawInterval = setInterval(() => {
          analyserRef.current.getFloatTimeDomainData(dataArrayRef.current);

          // Convert to absolute average values for smooth waveform
          const samples = 200;
          const blockSize = Math.floor(dataArrayRef.current.length / samples);
          const filteredData = [];

          for (let i = 0; i < samples; i++) {
            let sum = 0;
            for (let j = 0; j < blockSize; j++) {
              const val = dataArrayRef.current[i * blockSize + j];
              sum += Math.abs(val);
            }
            filteredData.push(sum / blockSize);
          }

          setWaveform(filteredData);
        }, 100);

        // MediaRecorder setup
        mediaRecorderRef.current = new MediaRecorder(stream);
        mediaRecorderRef.current.ondataavailable = (e) => {
          chunksRef.current.push(e.data);
        };

        mediaRecorderRef.current.onstop = async () => {
          const blob = new Blob(chunksRef.current, { type: "audio/webm" });
          chunksRef.current = [];

          const formData = new FormData();
          formData.append("audio", blob, "recording.webm");

          try {
            const res = await axios.post("http://localhost:5000/api/loudness/predict", formData, {
              headers: { "Content-Type": "multipart/form-data" },
            });

            const label = res.data.prediction;
            setPrediction(label);

            if (label === "Acceptable") setWaveColor("green");
            else if (label === "Low") setWaveColor("red");
            else setWaveColor("#3498db");
          } catch (err) {
            console.error("Prediction error:", err);
            setPrediction("Prediction error");
            setWaveColor("gray");
          }

          // Restart recording
          mediaRecorderRef.current.start();
          setTimeout(() => mediaRecorderRef.current.stop(), 300);
        };

        // Start first recording cycle
        mediaRecorderRef.current.start();
        setTimeout(() => mediaRecorderRef.current.stop(), 300);

        // Clean up
        return () => {
          clearInterval(drawInterval);
          audioContextRef.current?.close();
        };
      } catch (err) {
        console.error("Microphone error:", err);
        setPrediction("Microphone access error");
      }
    };

    startAudio();
  }, []);

  return (
    <div className="text-white px-120 py-68">
      <h2 className="text-2xl font-bold mb-6 px-22">üîä Real-Time Loudness Detector</h2>

      <div className="mb-6 w-full max-w-xl">
        <canvas
          ref={canvasRef}
          width={600}
          height={150}
          style={{
            border: "1px solid #ccc",
            borderRadius: "8px",
            background: "#fff",
          }}
        />
      </div>

      <div className="px-38">
      <div
        className={`p-6 rounded-xl shadow-lg w-[262px] ${
          prediction === "Acceptable"
            ? "bg-green-100 text-green-800"
            : prediction === "Low / Silent"
            ? "bg-red-100 text-red-800"
            : "bg-white text-[#003b46]"
        }`}
      >
        <p className="text-lg font-semibold">Prediction: {prediction}</p>
      </div>
    </div>
    </div>
  );
};

export default Dashboard;




import React, { useState, useRef, useEffect } from "react";
import { ReactMediaRecorder } from "react-media-recorder";

const SustainedVowel = () => {
  const [audioURL, setAudioURL] = useState("");
  const [results, setResults] = useState(null);
  const [volumeChunks, setVolumeChunks] = useState([]);
  const [isLive, setIsLive] = useState(false);

  const audioRef = useRef();
  const staticCanvasRef = useRef();
  const liveCanvasRef = useRef();

  const audioContextRef = useRef(null);
  const analyserRef = useRef(null);
  const dataArrayRef = useRef(null);
  const animationFrameRef = useRef(null);

  // üî¥ Start real-time waveform
  const startLiveWaveform = async () => {
    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
    const audioContext = new (window.AudioContext || window.webkitAudioContext)();
    const analyser = audioContext.createAnalyser();
    const source = audioContext.createMediaStreamSource(stream);

    analyser.fftSize = 2048;
    const bufferLength = analyser.fftSize;
    const dataArray = new Uint8Array(bufferLength);

    source.connect(analyser);

    audioContextRef.current = audioContext;
    analyserRef.current = analyser;
    dataArrayRef.current = dataArray;
    setIsLive(true);
    drawLiveWaveform();
  };

  // üõë Stop live waveform
  const stopLiveWaveform = () => {
    setIsLive(false);
    if (animationFrameRef.current) cancelAnimationFrame(animationFrameRef.current);
    audioContextRef.current?.close();
  };

  // üé® Draw live waveform
  const drawLiveWaveform = () => {
    if (!isLive) return;
    const canvas = liveCanvasRef.current;
    const ctx = canvas.getContext("2d");
    const analyser = analyserRef.current;
    const dataArray = dataArrayRef.current;

    animationFrameRef.current = requestAnimationFrame(drawLiveWaveform);

    analyser.getByteTimeDomainData(dataArray);
    ctx.fillStyle = "#ffffff";
    ctx.fillRect(0, 0, canvas.width, canvas.height);

    ctx.lineWidth = 2;
    ctx.strokeStyle = "#34d399"; // green
    ctx.beginPath();

    const sliceWidth = (canvas.width * 1.0) / dataArray.length;
    let x = 0;

    for (let i = 0; i < dataArray.length; i++) {
      const v = dataArray[i] / 128.0;
      const y = (v * canvas.height) / 2;
      i === 0 ? ctx.moveTo(x, y) : ctx.lineTo(x, y);
      x += sliceWidth;
    }

    ctx.lineTo(canvas.width, canvas.height / 2);
    ctx.stroke();
  };

  // üìä Analyze recorded audio
  const analyzeAudio = async (blob) => {
    const arrayBuffer = await blob.arrayBuffer();
    const audioContext = new AudioContext();
    const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);

    const rawData = audioBuffer.getChannelData(0);
    const duration = audioBuffer.duration;

    let total = 0;
    for (let i = 0; i < rawData.length; i++) {
      total += rawData[i] * rawData[i];
    }
    const rms = Math.sqrt(total / rawData.length);

    const CHUNK = 2048;
    let chunks = [];
    for (let i = 0; i < rawData.length; i += CHUNK) {
      const chunk = rawData.slice(i, i + CHUNK);
      let sum = 0;
      for (let j = 0; j < chunk.length; j++) {
        sum += chunk[j] * chunk[j];
      }
      chunks.push(Math.sqrt(sum / chunk.length));
    }

    const mean = chunks.reduce((a, b) => a + b, 0) / chunks.length;
    const variance = chunks.reduce((a, b) => a + Math.pow(b - mean, 2), 0) / chunks.length;
    const steadiness = 1 - Math.sqrt(variance);

    setVolumeChunks(chunks);
    setResults({
      duration: duration.toFixed(2),
      rms: rms.toFixed(4),
      steadiness: steadiness.toFixed(4),
    });
  };

  // üìà Static waveform (after recording)
  useEffect(() => {
    if (!volumeChunks.length) return;

    const canvas = staticCanvasRef.current;
    const ctx = canvas.getContext("2d");

    ctx.clearRect(0, 0, canvas.width, canvas.height);
    ctx.strokeStyle = "#6366f1";
    ctx.lineWidth = 2;
    ctx.beginPath();

    const width = canvas.width;
    const height = canvas.height;
    const step = width / volumeChunks.length;

    for (let i = 0; i < volumeChunks.length; i++) {
      const x = i * step;
      const y = height - volumeChunks[i] * height;
      if (i === 0) ctx.moveTo(x, y);
      else ctx.lineTo(x, y);
    }

    ctx.stroke();
  }, [volumeChunks]);

  return (
    <div className="max-w-xl mx-auto p-6 bg-white shadow-xl rounded-xl text-black">
      <h2 className="text-2xl font-bold mb-4 text-black">Sustained Vowel Phonation</h2>
      <p className="mb-4 text-black">
        Say and hold a vowel sound like ‚Äúah‚Äù or ‚Äúee‚Äù steadily for as long as possible.
      </p>

      <ReactMediaRecorder
        audio
        onStart={startLiveWaveform}
        onStop={(blobUrl, blob) => {
          stopLiveWaveform();
          setAudioURL(blobUrl);
          analyzeAudio(blob);
        }}
        render={({ status, startRecording, stopRecording }) => (
          <div>
            <p className="mb-2 text-black">Status: {status}</p>
            <div className="space-x-4">
              <button
                onClick={startRecording}
                className="bg-green-500 text-white px-4 py-2 rounded hover:bg-green-600"
              >
                Start
              </button>
              <button
                onClick={stopRecording}
                className="bg-red-500 text-white px-4 py-2 rounded hover:bg-red-600"
              >
                Stop
              </button>
            </div>

            {/* üî¥ Real-time waveform */}
            {isLive && (
              <div className="mt-4">
                <h4 className="font-semibold mb-1">Live Waveform:</h4>
                <canvas
                  ref={liveCanvasRef}
                  width={400}
                  height={100}
                  className="border border-green-300 rounded bg-white"
                />
              </div>
            )}

            {audioURL && (
              <div className="mt-4">
                <p className="mb-1 font-semibold text-black">Playback:</p>
                <audio ref={audioRef} controls src={audioURL} />
              </div>
            )}
          </div>
        )}
      />

      {/* üìä Analysis results + static waveform */}
      {results && (
        <div className="mt-6 p-4 border border-gray-300 rounded text-black bg-gray-50">
          <h3 className="font-semibold mb-2 text-black">Analysis Results:</h3>
          <p><strong>Duration:</strong> {results.duration} seconds</p>
          <p><strong>Average Volume (RMS):</strong> {results.rms}</p>
          <p><strong>Steadiness Score:</strong> {results.steadiness}</p>
          <p className="mt-2">
            {results.steadiness > 0.95
              ? "Excellent! Your voice was steady."
              : "Try to hold your voice more steadily next time."}
          </p>
          <div className="mt-6">
            <h4 className="font-semibold mb-2">Volume Waveform:</h4>
            <canvas
              ref={staticCanvasRef}
              width={400}
              height={100}
              className="border border-gray-300 rounded bg-white"
            />
          </div>
        </div>
      )}
    </div>
  );
};

export default SustainedVowel;